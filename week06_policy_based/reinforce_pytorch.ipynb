{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efgs4wdEyU1f"
      },
      "source": [
        "# REINFORCE in PyTorch\n",
        "\n",
        "Just like we did before for Q-learning, this time we'll design a PyTorch network to learn `CartPole-v0` via policy gradient (REINFORCE).\n",
        "\n",
        "Most of the code in this notebook is taken from approximate Q-learning, so you'll find it more or less familiar and even simpler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVaFXKRwyU1g",
        "outputId": "0147e777-afd7-4f04-909d-fde86139d998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "(Reading database ... 123634 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../1-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../3-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../5-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../7-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.12_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../8-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.12_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.36.1)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio_ffmpeg>=0.2.0->moviepy) (75.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.12.14)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 50 not upgraded.\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg) (75.1.0)\n",
            "Starting virtual X frame buffer: Xvfb.\n"
          ]
        }
      ],
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "    !pip install -q gymnasium\n",
        "    !pip install moviepy\n",
        "    !apt install ffmpeg\n",
        "    !pip install imageio-ffmpeg\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4HOq-CpryU1h"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAru4d4VyU1i"
      },
      "outputs": [],
      "source": [
        "# also you need to install ffmpeg if not installed\n",
        "# for MacOS: ! brew install ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8-BpqdYyU1i"
      },
      "source": [
        "A caveat: with some versions of `pyglet`, the following cell may crash with `NameError: name 'base' is not defined`. The corresponding bug report is [here](https://github.com/pyglet/pyglet/issues/134). If you see this error, try restarting the kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "AATaX0SYyU1j",
        "outputId": "0c539f61-0b69-4e84-92a4-398f33cd75c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7d02cdcf92a0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAF7CAYAAAD4/3BBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApaElEQVR4nO3df3RU9Z3/8ddMkgmEMBMDJJNIgigKRgi2oGHW1tKSEiK6UuM5alnBliNHNvFUYy2ma1Xsfo2re9YfXYWzZ3fFPUeKtV/RQgWLQUKtETUlS0DJCoc2WDIJymYmCWbyYz7fP1zmu6MImSRkPkOej3PuOZn7+cyd9/0cTvLicz/3jsMYYwQAAGARZ7wLAAAA+CICCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwTlwDyjPPPKMLLrhAY8aMUVFRkd599914lgMAACwRt4Dy4osvqrKyUg8++KD++Mc/avbs2SopKVFbW1u8SgIAAJZwxOvLAouKinTFFVfon//5nyVJ4XBYeXl5uvPOO3XffffFoyQAAGCJ5Hh8aE9Pj+rr61VVVRXZ53Q6VVxcrLq6ui/1D4VCCoVCkdfhcFjHjx/XhAkT5HA4RqRmAAAwNMYYdXR0KDc3V07n6S/ixCWgfPLJJ+rv71d2dnbU/uzsbB04cOBL/aurq7VmzZqRKg8AAJxFR44c0eTJk0/bJy4BJVZVVVWqrKyMvA4EAsrPz9eRI0fkdrvjWBkAABioYDCovLw8jR8//ox94xJQJk6cqKSkJLW2tkbtb21tldfr/VL/1NRUpaamfmm/2+0moAAAkGAGsjwjLnfxuFwuzZkzRzU1NZF94XBYNTU18vl88SgJAABYJG6XeCorK7V8+XLNnTtXV155pZ588kl1dXXpBz/4QbxKAgAAlohbQLnpppt07NgxPfDAA/L7/br88su1bdu2Ly2cBQAAo0/cnoMyFMFgUB6PR4FAgDUoAAAkiFj+fvNdPAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1hn2gPLQQw/J4XBEbTNmzIi0d3d3q7y8XBMmTFB6errKysrU2to63GUAAIAEdlZmUC677DK1tLREtrfeeivSdvfdd2vz5s166aWXVFtbq6NHj+qGG244G2UAAIAElXxWDpqcLK/X+6X9gUBA//Zv/6YNGzboO9/5jiTpueee06WXXqp33nlH8+bNOxvlAACABHNWZlA++ugj5ebm6sILL9TSpUvV3NwsSaqvr1dvb6+Ki4sjfWfMmKH8/HzV1dV95fFCoZCCwWDUBgAAzl3DHlCKioq0fv16bdu2TWvXrtXhw4f1zW9+Ux0dHfL7/XK5XMrIyIh6T3Z2tvx+/1ces7q6Wh6PJ7Ll5eUNd9kAAMAiw36Jp7S0NPJzYWGhioqKNGXKFP3qV7/S2LFjB3XMqqoqVVZWRl4Hg0FCCgAA57CzfptxRkaGLrnkEh08eFBer1c9PT1qb2+P6tPa2nrKNSsnpaamyu12R20AAODcddYDSmdnpw4dOqScnBzNmTNHKSkpqqmpibQ3NTWpublZPp/vbJcCAAASxLBf4vnxj3+s6667TlOmTNHRo0f14IMPKikpSbfccos8Ho9WrFihyspKZWZmyu12684775TP5+MOHgAAEDHsAeXjjz/WLbfcok8//VSTJk3SN77xDb3zzjuaNGmSJOmJJ56Q0+lUWVmZQqGQSkpK9Oyzzw53GQAAIIE5jDEm3kXEKhgMyuPxKBAIsB4FAIAEEcvfb76LBwAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgnZgDyq5du3TdddcpNzdXDodDr7zySlS7MUYPPPCAcnJyNHbsWBUXF+ujjz6K6nP8+HEtXbpUbrdbGRkZWrFihTo7O4d0IgAA4NwRc0Dp6urS7Nmz9cwzz5yy/bHHHtPTTz+tdevWaffu3Ro3bpxKSkrU3d0d6bN06VLt379f27dv15YtW7Rr1y6tXLly8GcBAADOKQ5jjBn0mx0Obdq0SUuWLJH0+exJbm6u7rnnHv34xz+WJAUCAWVnZ2v9+vW6+eab9eGHH6qgoEDvvfee5s6dK0natm2brrnmGn388cfKzc094+cGg0F5PB4FAgG53e7Blg8AAEZQLH+/h3UNyuHDh+X3+1VcXBzZ5/F4VFRUpLq6OklSXV2dMjIyIuFEkoqLi+V0OrV79+5THjcUCikYDEZtAADg3DWsAcXv90uSsrOzo/ZnZ2dH2vx+v7KysqLak5OTlZmZGenzRdXV1fJ4PJEtLy9vOMsGAACWSYi7eKqqqhQIBCLbkSNH4l0SAAA4i4Y1oHi9XklSa2tr1P7W1tZIm9frVVtbW1R7X1+fjh8/HunzRampqXK73VEbAAA4dw1rQJk6daq8Xq9qamoi+4LBoHbv3i2fzydJ8vl8am9vV319faTPjh07FA6HVVRUNJzlAACABJUc6xs6Ozt18ODByOvDhw+roaFBmZmZys/P11133aW///u/18UXX6ypU6fqZz/7mXJzcyN3+lx66aVatGiRbr/9dq1bt069vb2qqKjQzTffPKA7eAAAwLkv5oDy/vvv69vf/nbkdWVlpSRp+fLlWr9+vX7yk5+oq6tLK1euVHt7u77xjW9o27ZtGjNmTOQ9L7zwgioqKrRgwQI5nU6VlZXp6aefHobTAQAA54IhPQclXngOCgAAiSduz0EBAAAYDgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWiTmg7Nq1S9ddd51yc3PlcDj0yiuvRLXfdtttcjgcUduiRYui+hw/flxLly6V2+1WRkaGVqxYoc7OziGdCAAAOHfEHFC6uro0e/ZsPfPMM1/ZZ9GiRWppaYlsv/zlL6Paly5dqv3792v79u3asmWLdu3apZUrV8ZePQAAOCclx/qG0tJSlZaWnrZPamqqvF7vKds+/PBDbdu2Te+9957mzp0rSfrFL36ha665Rv/4j/+o3NzcWEsCAADnmLOyBmXnzp3KysrS9OnTtWrVKn366aeRtrq6OmVkZETCiSQVFxfL6XRq9+7dpzxeKBRSMBiM2gAAwLlr2APKokWL9B//8R+qqanRP/zDP6i2tlalpaXq7++XJPn9fmVlZUW9Jzk5WZmZmfL7/ac8ZnV1tTweT2TLy8sb7rIBAIBFYr7EcyY333xz5OdZs2apsLBQF110kXbu3KkFCxYM6phVVVWqrKyMvA4Gg4QUAADOYWf9NuMLL7xQEydO1MGDByVJXq9XbW1tUX36+vp0/Pjxr1y3kpqaKrfbHbUBAIBz11kPKB9//LE+/fRT5eTkSJJ8Pp/a29tVX18f6bNjxw6Fw2EVFRWd7XIAAEACiPkST2dnZ2Q2RJIOHz6shoYGZWZmKjMzU2vWrFFZWZm8Xq8OHTqkn/zkJ5o2bZpKSkokSZdeeqkWLVqk22+/XevWrVNvb68qKip08803cwcPAACQJDmMMSaWN+zcuVPf/va3v7R/+fLlWrt2rZYsWaI9e/aovb1dubm5WrhwoX7+858rOzs70vf48eOqqKjQ5s2b5XQ6VVZWpqefflrp6ekDqiEYDMrj8SgQCHC5BwCABBHL3++YA4oNCCgAACSeWP5+8108AADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGCdmL8sEACG4rPjR3Vk9/89bZ+UNI+mfmvZCFUEwEYEFAAjqi/UpUBz42n7uMZPVLivV87klBGqCoBtuMQDwD7GKNzXE+8qAMQRAQWAfUyYgAKMcgQUANYxYgYFGO0IKADsY4z6CSjAqEZAAWAdwxoUYNQjoACwD2tQgFGPgALAOsygACCgABhRyWPSNTbz/NP2CfeF1Nl6aIQqAmAjAgqAEZXkGqtUd9Zp+5j+PoUCbSNUEQAbEVAAjCiH08kTYgGcEQEFwIhyOAgoAM6MgAJgZDmcciQRUACcHgEFwIhyOJ1yElAAnAEBBcCIcjgIKADOjIACYGQ5kliDAuCMCCgARtTAL/EYGWPOej0A7ERAATCiHA6H5Ew6Yz9jjGTCI1ARABsRUABYyYT7Fe7vi3cZAOIkpoBSXV2tK664QuPHj1dWVpaWLFmipqamqD7d3d0qLy/XhAkTlJ6errKyMrW2tkb1aW5u1uLFi5WWlqasrCzde++96uvjFxGA/8+E+2UIKMCoFVNAqa2tVXl5ud555x1t375dvb29Wrhwobq6uiJ97r77bm3evFkvvfSSamtrdfToUd1www2R9v7+fi1evFg9PT16++239fzzz2v9+vV64IEHhu+sACQ8ZlCA0c1hhrAK7dixY8rKylJtba2uvvpqBQIBTZo0SRs2bNCNN94oSTpw4IAuvfRS1dXVad68edq6dauuvfZaHT16VNnZ2ZKkdevWafXq1Tp27JhcLtcZPzcYDMrj8SgQCMjtdg+2fABx4m+s0ZG3Xzxtn3TvNF34nR8qdfzEEaoKwNkWy9/vIa1BCQQCkqTMzExJUn19vXp7e1VcXBzpM2PGDOXn56uurk6SVFdXp1mzZkXCiSSVlJQoGAxq//79p/ycUCikYDAYtQE4tzGDAoxugw4o4XBYd911l6666irNnDlTkuT3++VyuZSRkRHVNzs7W36/P9Lnf4eTk+0n206lurpaHo8nsuXl5Q22bAAJwoTDrEEBRrFBB5Ty8nLt27dPGzduHM56TqmqqkqBQCCyHTly5Kx/JoD4YpEsMLolD+ZNFRUV2rJli3bt2qXJkydH9nu9XvX09Ki9vT1qFqW1tVVerzfS591334063sm7fE72+aLU1FSlpqYOplQAFnImpciRlHzaABLuC6mv58QIVgXAJjHNoBhjVFFRoU2bNmnHjh2aOnVqVPucOXOUkpKimpqayL6mpiY1NzfL5/NJknw+nxobG9XW1hbps337drndbhUUFAzlXAAkiHGTLtDY83JP2ycUPKauY38eoYoA2CamGZTy8nJt2LBBr776qsaPHx9ZM+LxeDR27Fh5PB6tWLFClZWVyszMlNvt1p133imfz6d58+ZJkhYuXKiCggLdeuuteuyxx+T3+3X//fervLycWRJglHAkJcvhHNQELoBRIqbfEGvXrpUkzZ8/P2r/c889p9tuu02S9MQTT8jpdKqsrEyhUEglJSV69tlnI32TkpK0ZcsWrVq1Sj6fT+PGjdPy5cv18MMPD+1MACQMZ1KSHAN43D2A0WtIz0GJF56DAiS2UMdxHa5dr46/HDhtv/Ov/J5yv1Y6QlUBONtG7DkoADAYzqQkOZlBAXAaBBQAI441KADOhIACYMQ5nMmsQQFwWgQUACPu8xmUgQWUBFwmB2AYEFAAjDiHwymHcwC/fggnwKhFQAEw4hwOx4D6hft7ZcL9Z7kaADYioACwlunvlUw43mUAiAMCCgBrMYMCjF4EFADWCvf3yTCDAoxKBBQA1jJ9vTJhAgowGhFQAFiLSzzA6EVAAWAtwyUeYNQioACw1uczKAQUYDQioACIi4z8QiWPST9tn46Wj9TT8ekIVQTAJgQUAHGRPHb8Gb8w0LAGBRi1CCgA4sKZ7JIG+ERZAKMPAQVAXDiTXXI4+BUE4NT47QAgLhzJKcygAPhKBBQAcZGUxAwKgK/GbwcAceFIdg34W40BjD4EFABxkZScIjGDAuAr8NsBQFw4klIGNINiTFjGmBGoCIBNCCgA4mKgl3dMf+9ZrgSAjQgoAKzW39cjMYMCjDoEFABWC/eGJBFQgNGGgALAauG+HtagAKMQAQWA1cJ9zKAAoxEBBYDVwr2sQQFGIwIKAKv194XIJ8AoREABEDcpaZ4z9unp+EQy/SNQDQCbEFAAxE3mRXPP+DTZ9j/v/fxWYwCjSkwBpbq6WldccYXGjx+vrKwsLVmyRE1NTVF95s+fL4fDEbXdcccdUX2am5u1ePFipaWlKSsrS/fee6/6+vqGfjYAEoozZUy8SwBgqeRYOtfW1qq8vFxXXHGF+vr69NOf/lQLFy7UBx98oHHjxkX63X777Xr44Ycjr9PS0iI/9/f3a/HixfJ6vXr77bfV0tKiZcuWKSUlRY888sgwnBKAROFMSZXD4WCNCYAviSmgbNu2Ler1+vXrlZWVpfr6el199dWR/WlpafJ6vac8xu9+9zt98MEHeuONN5Sdna3LL79cP//5z7V69Wo99NBDcrlcgzgNAIkoKSU13iUAsNSQ1qAEAgFJUmZmZtT+F154QRMnTtTMmTNVVVWlEydORNrq6uo0a9YsZWdnR/aVlJQoGAxq//79p/ycUCikYDAYtQFIfE4CCoCvENMMyv8WDod111136aqrrtLMmTMj+7///e9rypQpys3N1d69e7V69Wo1NTXp5ZdfliT5/f6ocCIp8trv95/ys6qrq7VmzZrBlgrAUkmsQQHwFQYdUMrLy7Vv3z699dZbUftXrlwZ+XnWrFnKycnRggULdOjQIV100UWD+qyqqipVVlZGXgeDQeXl5Q2ucADW+PwSz8C+1RjA6DKoSzwVFRXasmWL3nzzTU2ePPm0fYuKiiRJBw8elCR5vV61trZG9Tn5+qvWraSmpsrtdkdtABKfM5lLPABOLaaAYoxRRUWFNm3apB07dmjq1KlnfE9DQ4MkKScnR5Lk8/nU2Niotra2SJ/t27fL7XaroKAglnIAJDhnSurAJlCM4QsDgVEmpks85eXl2rBhg1599VWNHz8+smbE4/Fo7NixOnTokDZs2KBrrrlGEyZM0N69e3X33Xfr6quvVmFhoSRp4cKFKigo0K233qrHHntMfr9f999/v8rLy5Wayv+mgNHEcYaHtJ0U7u89y5UAsE1MMyhr165VIBDQ/PnzlZOTE9lefPFFSZLL5dIbb7yhhQsXasaMGbrnnntUVlamzZs3R46RlJSkLVu2KCkpST6fT3/zN3+jZcuWRT03BQD+t3BPd7xLADDCYppBOdMUa15enmpra894nClTpui1116L5aMBjGJ9vQQUYLThu3gAWC/cG4p3CQBGGAEFgPX6mUEBRh0CCgDrsQYFGH0IKACsxwwKMPoQUABYr581KMCoQ0ABEFdZBfPP2Ke18Y2zXwgAqxBQAMRV8tjxZ+wT7usZgUoA2ISAAiCuPv/CQACIRkABEFdJKWPiXQIACxFQAMSVk4AC4BQIKADiiks8AE6FgAIgrpJczKAA+DICCoC4ciYTUAB8GQEFQFwxgwLgVAgoAOLG4XDI4UwaUF/T33eWqwFgEwIKgARg1N/H4+6B0YSAAiAhhPk+HmBUIaAAsJ/hG42B0YaAAiAhMIMCjC7J8S4AQOLr6xv8Atb+AS1+NerpPjGkz5Ekp9Mpp5P/lwGJgIACYMimT5+u5ubmQb13oidNv/k/N522T09Pj2684Xr9fu/gPuOkzZs3a9GiRUM6BoCRQUABMGR9fX2Dnt0Y6PtcSY4hz6AYY4b0fgAjh7lOAHHV29evA38+Fnn9SU+uDp2YrY9OfF0fd1+iUHiMkpxOzbkkJ45VAhhpzKAAiKue3n7t/9MxzZgySQf/J5R0h8fJyKEUR48+7p6ur7t/p8umZsW7VAAjiBkUAHEVNkaf9fTr8GezdOjE5fos7JZRkiSnes0Y/Xdfjt5uv0FhM7AnzgI4NxBQAMSVMdLHndk60DVP4a+Y1P0snK66wJKRLQxAXBFQAMSVkdFnPX2SHKfp5ZA5bTuAcw0BBUBcGSN19/TGuwwAliGgAIgrY4w+C/FNxQCiEVAAxFXYGI0zzZqW9r4cCp+yT4qjW0WezSNcGYB4iimgrF27VoWFhXK73XK73fL5fNq6dWukvbu7W+Xl5ZowYYLS09NVVlam1tbWqGM0Nzdr8eLFSktLU1ZWlu69994hP3wJQOIyRgr19Gja2D/qgrGNcjlO/E9QMUpy9Cg96biuPu9FpTj4Lh5gNInpOSiTJ0/Wo48+qosvvljGGD3//PO6/vrrtWfPHl122WW6++679dvf/lYvvfSSPB6PKioqdMMNN+gPf/iDJKm/v1+LFy+W1+vV22+/rZaWFi1btkwpKSl65JFHzsoJArDfXz4J6tU/HJB0QK2hC/TffV71m2SlJQWUm3pIrzlPqO2/u+JdJoAR5DBDfPZzZmamHn/8cd14442aNGmSNmzYoBtvvFGSdODAAV166aWqq6vTvHnztHXrVl177bU6evSosrOzJUnr1q3T6tWrdezYMblcrgF9ZjAYlMfj0W233Tbg9wA4ezZs2KDOzs54l3FGpaWlysvLi3cZwKjV09Oj9evXKxAIyO12n7bvoJ8k29/fr5deekldXV3y+Xyqr69Xb2+viouLI31mzJih/Pz8SECpq6vTrFmzIuFEkkpKSrRq1Srt379fX/va1075WaFQSKHQ/5/eDQaDkqRbb71V6enpgz0FAMPkN7/5TUIElJKSEvl8vniXAYxanZ2dWr9+/YD6xhxQGhsb5fP51N3drfT0dG3atEkFBQVqaGiQy+VSRkZGVP/s7Gz5/X5Jkt/vjwonJ9tPtn2V6upqrVmz5kv7586de8YEBuDsS5SZzEsuuURXXnllvMsARq2TEwwDEfNdPNOnT1dDQ4N2796tVatWafny5frggw9iPUxMqqqqFAgEItuRI0fO6ucBAID4inkGxeVyadq0aZKkOXPm6L333tNTTz2lm266ST09PWpvb4+aRWltbZXX65Ukeb1evfvuu1HHO3mXz8k+p5KamqrU1NRYSwUAAAlqyM9BCYfDCoVCmjNnjlJSUlRTUxNpa2pqUnNzc+Sar8/nU2Njo9ra2iJ9tm/fLrfbrYKCgqGWAgAAzhExzaBUVVWptLRU+fn56ujo0IYNG7Rz5069/vrr8ng8WrFihSorK5WZmSm3260777xTPp9P8+bNkyQtXLhQBQUFuvXWW/XYY4/J7/fr/vvvV3l5OTMkAAAgIqaA0tbWpmXLlqmlpUUej0eFhYV6/fXX9d3vfleS9MQTT8jpdKqsrEyhUEglJSV69tlnI+9PSkrSli1btGrVKvl8Po0bN07Lly/Xww8/PLxnBQAAEtqQn4MSDyefgzKQ+6gBnH1TpkxRc3NzvMs4o9dee02lpaXxLgMYtWL5+8138QAAAOsQUAAAgHUIKAAAwDoEFAAAYJ1BfxcPAJxUUlKiY8eOxbuMM/riV20AsBcBBcCQ/cu//Eu8SwBwjuESDwAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYJ2YAsratWtVWFgot9stt9stn8+nrVu3Rtrnz58vh8MRtd1xxx1Rx2hubtbixYuVlpamrKws3Xvvverr6xueswEAAOeE5Fg6T548WY8++qguvvhiGWP0/PPP6/rrr9eePXt02WWXSZJuv/12Pfzww5H3pKWlRX7u7+/X4sWL5fV69fbbb6ulpUXLli1TSkqKHnnkkWE6JQAAkOgcxhgzlANkZmbq8ccf14oVKzR//nxdfvnlevLJJ0/Zd+vWrbr22mt19OhRZWdnS5LWrVun1atX69ixY3K5XAP6zGAwKI/Ho0AgILfbPZTyAQDACInl7/eg16D09/dr48aN6urqks/ni+x/4YUXNHHiRM2cOVNVVVU6ceJEpK2urk6zZs2KhBNJKikpUTAY1P79+7/ys0KhkILBYNQGAADOXTFd4pGkxsZG+Xw+dXd3Kz09XZs2bVJBQYEk6fvf/76mTJmi3Nxc7d27V6tXr1ZTU5NefvllSZLf748KJ5Iir/1+/1d+ZnV1tdasWRNrqQAAIEHFHFCmT5+uhoYGBQIB/frXv9by5ctVW1urgoICrVy5MtJv1qxZysnJ0YIFC3To0CFddNFFgy6yqqpKlZWVkdfBYFB5eXmDPh4AALBbzJd4XC6Xpk2bpjlz5qi6ulqzZ8/WU089dcq+RUVFkqSDBw9Kkrxer1pbW6P6nHzt9Xq/8jNTU1Mjdw6d3AAAwLlryM9BCYfDCoVCp2xraGiQJOXk5EiSfD6fGhsb1dbWFumzfft2ud3uyGUiAACAmC7xVFVVqbS0VPn5+ero6NCGDRu0c+dOvf766zp06JA2bNiga665RhMmTNDevXt199136+qrr1ZhYaEkaeHChSooKNCtt96qxx57TH6/X/fff7/Ky8uVmpp6Vk4QAAAknpgCSltbm5YtW6aWlhZ5PB4VFhbq9ddf13e/+10dOXJEb7zxhp588kl1dXUpLy9PZWVluv/++yPvT0pK0pYtW7Rq1Sr5fD6NGzdOy5cvj3puCgAAwJCfgxIPPAcFAIDEMyLPQQEAADhbCCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHWS413AYBhjJEnBYDDOlQAAgIE6+Xf75N/x00nIgNLR0SFJysvLi3MlAAAgVh0dHfJ4PKft4zADiTGWCYfDampqUkFBgY4cOSK32x3vkhJWMBhUXl4e4zgMGMvhw1gOD8Zx+DCWw8MYo46ODuXm5srpPP0qk4ScQXE6nTr//PMlSW63m38sw4BxHD6M5fBhLIcH4zh8GMuhO9PMyUkskgUAANYhoAAAAOskbEBJTU3Vgw8+qNTU1HiXktAYx+HDWA4fxnJ4MI7Dh7EceQm5SBYAAJzbEnYGBQAAnLsIKAAAwDoEFAAAYB0CCgAAsE5CBpRnnnlGF1xwgcaMGaOioiK9++678S7JOrt27dJ1112n3NxcORwOvfLKK1Htxhg98MADysnJ0dixY1VcXKyPPvooqs/x48e1dOlSud1uZWRkaMWKFers7BzBs4i/6upqXXHFFRo/fryysrK0ZMkSNTU1RfXp7u5WeXm5JkyYoPT0dJWVlam1tTWqT3NzsxYvXqy0tDRlZWXp3nvvVV9f30ieSlytXbtWhYWFkYdc+Xw+bd26NdLOGA7eo48+KofDobvuuiuyj/EcmIceekgOhyNqmzFjRqSdcYwzk2A2btxoXC6X+fd//3ezf/9+c/vtt5uMjAzT2toa79Ks8tprr5m/+7u/My+//LKRZDZt2hTV/uijjxqPx2NeeeUV85//+Z/mr//6r83UqVPNZ599FumzaNEiM3v2bPPOO++Y3//+92batGnmlltuGeEzia+SkhLz3HPPmX379pmGhgZzzTXXmPz8fNPZ2Rnpc8cdd5i8vDxTU1Nj3n//fTNv3jzzV3/1V5H2vr4+M3PmTFNcXGz27NljXnvtNTNx4kRTVVUVj1OKi9/85jfmt7/9rfmv//ov09TUZH7605+alJQUs2/fPmMMYzhY7777rrngggtMYWGh+dGPfhTZz3gOzIMPPmguu+wy09LSEtmOHTsWaWcc4yvhAsqVV15pysvLI6/7+/tNbm6uqa6ujmNVdvtiQAmHw8br9ZrHH388sq+9vd2kpqaaX/7yl8YYYz744AMjybz33nuRPlu3bjUOh8P85S9/GbHabdPW1mYkmdraWmPM5+OWkpJiXnrppUifDz/80EgydXV1xpjPw6LT6TR+vz/SZ+3atcbtdptQKDSyJ2CR8847z/zrv/4rYzhIHR0d5uKLLzbbt2833/rWtyIBhfEcuAcffNDMnj37lG2MY/wl1CWenp4e1dfXq7i4OLLP6XSquLhYdXV1cawssRw+fFh+vz9qHD0ej4qKiiLjWFdXp4yMDM2dOzfSp7i4WE6nU7t37x7xmm0RCAQkSZmZmZKk+vp69fb2Ro3ljBkzlJ+fHzWWs2bNUnZ2dqRPSUmJgsGg9u/fP4LV26G/v18bN25UV1eXfD4fYzhI5eXlWrx4cdS4SfybjNVHH32k3NxcXXjhhVq6dKmam5slMY42SKgvC/zkk0/U398f9Y9BkrKzs3XgwIE4VZV4/H6/JJ1yHE+2+f1+ZWVlRbUnJycrMzMz0me0CYfDuuuuu3TVVVdp5syZkj4fJ5fLpYyMjKi+XxzLU431ybbRorGxUT6fT93d3UpPT9emTZtUUFCghoYGxjBGGzdu1B//+Ee99957X2rj3+TAFRUVaf369Zo+fbpaWlq0Zs0affOb39S+ffsYRwskVEAB4qm8vFz79u3TW2+9Fe9SEtL06dPV0NCgQCCgX//611q+fLlqa2vjXVbCOXLkiH70ox9p+/btGjNmTLzLSWilpaWRnwsLC1VUVKQpU6boV7/6lcaOHRvHyiAl2F08EydOVFJS0pdWUbe2tsrr9capqsRzcqxON45er1dtbW1R7X19fTp+/PioHOuKigpt2bJFb775piZPnhzZ7/V61dPTo/b29qj+XxzLU431ybbRwuVyadq0aZozZ46qq6s1e/ZsPfXUU4xhjOrr69XW1qavf/3rSk5OVnJysmpra/X0008rOTlZ2dnZjOcgZWRk6JJLLtHBgwf5d2mBhAooLpdLc+bMUU1NTWRfOBxWTU2NfD5fHCtLLFOnTpXX640ax2AwqN27d0fG0efzqb29XfX19ZE+O3bsUDgcVlFR0YjXHC/GGFVUVGjTpk3asWOHpk6dGtU+Z84cpaSkRI1lU1OTmpubo8aysbExKvBt375dbrdbBQUFI3MiFgqHwwqFQoxhjBYsWKDGxkY1NDREtrlz52rp0qWRnxnPwens7NShQ4eUk5PDv0sbxHuVbqw2btxoUlNTzfr1680HH3xgVq5caTIyMqJWUePzFf579uwxe/bsMZLMP/3TP5k9e/aYP//5z8aYz28zzsjIMK+++qrZu3evuf766095m/HXvvY1s3v3bvPWW2+Ziy++eNTdZrxq1Srj8XjMzp07o25FPHHiRKTPHXfcYfLz882OHTvM+++/b3w+n/H5fJH2k7ciLly40DQ0NJht27aZSZMmjapbEe+77z5TW1trDh8+bPbu3Wvuu+8+43A4zO9+9ztjDGM4VP/7Lh5jGM+Buueee8zOnTvN4cOHzR/+8AdTXFxsJk6caNra2owxjGO8JVxAMcaYX/ziFyY/P9+4XC5z5ZVXmnfeeSfeJVnnzTffNJK+tC1fvtwY8/mtxj/72c9Mdna2SU1NNQsWLDBNTU1Rx/j000/NLbfcYtLT043b7TY/+MEPTEdHRxzOJn5ONYaSzHPPPRfp89lnn5m//du/Needd55JS0sz3/ve90xLS0vUcf70pz+Z0tJSM3bsWDNx4kRzzz33mN7e3hE+m/j54Q9/aKZMmWJcLpeZNGmSWbBgQSScGMMYDtUXAwrjOTA33XSTycnJMS6Xy5x//vnmpptuMgcPHoy0M47x5TDGmPjM3QAAAJxaQq1BAQAAowMBBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADW+X999ClitFiWCwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "\n",
        "# gym compatibility: unwrap TimeLimit\n",
        "if hasattr(env, '_max_episode_steps'):\n",
        "    env = env.env\n",
        "\n",
        "env.reset()\n",
        "n_actions = env.action_space.n\n",
        "state_dim = env.observation_space.shape\n",
        "\n",
        "plt.imshow(env.render())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xd4juOoyU1j"
      },
      "source": [
        "# Building the network for REINFORCE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIqWC71UyU1k"
      },
      "source": [
        "For REINFORCE algorithm, we'll need a model that predicts action probabilities given states.\n",
        "\n",
        "For numerical stability, please __do not include the softmax layer into your network architecture__.\n",
        "We'll use softmax or log-softmax where appropriate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "B0tLtBnEyU1k"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RSSwjjjyU1l",
        "outputId": "29717e25-ed5c-47ea-977d-ba07ae228791"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 2\n"
          ]
        }
      ],
      "source": [
        "# Build a simple neural network that predicts policy logits.\n",
        "# Keep it simple: CartPole isn't worth deep architectures.\n",
        "n_inputs = env.reset()[0].shape[0]\n",
        "n_hidden = 16\n",
        "n_outputs = env.action_space.n\n",
        "print(n_inputs, n_outputs)\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(n_inputs, n_hidden),\n",
        "    # nn.BatchNorm1d(n_hidden),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Linear(n_hidden, n_hidden),\n",
        "    # nn.BatchNorm1d(n_hidden),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Linear(n_hidden, n_outputs),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ahdnFbyU1m"
      },
      "source": [
        "#### Predict function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcGLoV9pyU1m"
      },
      "source": [
        "Note: output value of this function is not a torch tensor, it's a numpy array.\n",
        "So, here gradient calculation is not needed.\n",
        "<br>\n",
        "Use [no_grad](https://pytorch.org/docs/stable/autograd.html#torch.autograd.no_grad)\n",
        "to suppress gradient calculation.\n",
        "<br>\n",
        "Also, `.detach()` (or legacy `.data` property) can be used instead, but there is a difference:\n",
        "<br>\n",
        "With `.detach()` computational graph is built but then disconnected from a particular tensor,\n",
        "so `.detach()` should be used if that graph is needed for backprop via some other (not detached) tensor;\n",
        "<br>\n",
        "In contrast, no graph is built by any operation in `no_grad()` context, thus it's preferable here."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cpu\""
      ],
      "metadata": {
        "id": "x275klweNPV_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "i-4L5BCtyU1m"
      },
      "outputs": [],
      "source": [
        "def predict_probs(states):\n",
        "    \"\"\"\n",
        "    Predict action probabilities given states.\n",
        "    :param states: numpy array of shape [batch, state_shape]\n",
        "    :returns: numpy array of shape [batch, n_actions]\n",
        "    \"\"\"\n",
        "    # convert states, compute logits, use softmax to get probability\n",
        "    states = torch.from_numpy(states).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(states)\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "\n",
        "    return probs.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()[0].shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XVpl-YJNcwD",
        "outputId": "a0fb66c9-1a23-4cb0-a8a9-825581c20b47"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "rjeU88vMyU1m"
      },
      "outputs": [],
      "source": [
        "test_states = np.array([env.reset()[0] for _ in range(5)])\n",
        "test_probas = predict_probs(test_states)\n",
        "assert isinstance(test_probas, np.ndarray), \\\n",
        "    \"you must return np array and not %s\" % type(test_probas)\n",
        "assert tuple(test_probas.shape) == (test_states.shape[0], env.action_space.n), \\\n",
        "    \"wrong output shape: %s\" % str(np.shape(test_probas))\n",
        "assert np.allclose(np.sum(test_probas, axis=1), 1), \"probabilities do not sum to 1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsKrnycWyU1m"
      },
      "source": [
        "### Play the game\n",
        "\n",
        "We can now use our newly built agent to play the game."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "24iSwdvCyU1m"
      },
      "outputs": [],
      "source": [
        "def generate_session(env, t_max=1000):\n",
        "    \"\"\"\n",
        "    Play a full session with REINFORCE agent.\n",
        "    Returns sequences of states, actions, and rewards.\n",
        "    \"\"\"\n",
        "    # arrays to record session\n",
        "    states, actions, rewards = [], [], []\n",
        "\n",
        "    s = env.reset()[0]\n",
        "\n",
        "    for t in range(t_max):\n",
        "        # action probabilities array aka pi(a|s)\n",
        "        action_probs = predict_probs(np.array([s]))[0]\n",
        "\n",
        "        # Sample action with given probabilities.\n",
        "        a = np.random.choice(env.action_space.n, p=action_probs)\n",
        "\n",
        "        new_s, r, terminated, truncated, info = env.step(a)\n",
        "\n",
        "        # record session history to train later\n",
        "        states.append(s)\n",
        "        actions.append(a)\n",
        "        rewards.append(r)\n",
        "\n",
        "        s = new_s\n",
        "        if terminated or truncated:\n",
        "            break\n",
        "\n",
        "    return states, actions, rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "-7u6Xhc4yU1n"
      },
      "outputs": [],
      "source": [
        "# test it\n",
        "states, actions, rewards = generate_session(env)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# everything -- for only ONE session\n",
        "# e.g. states of ONE session: s0, s1, s2, ... si\n",
        "states"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMMo7s97O_jZ",
        "outputId": "8f79f1fd-f3f8-4d4c-e96c-9a699ed5af32"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([-0.01313536,  0.0135184 , -0.01926952, -0.0060758 ], dtype=float32),\n",
              " array([-0.012865  , -0.18132196, -0.01939103,  0.2804656 ], dtype=float32),\n",
              " array([-0.01649144, -0.37616202, -0.01378172,  0.56697017], dtype=float32),\n",
              " array([-0.02401468, -0.18084948, -0.00244232,  0.26997745], dtype=float32),\n",
              " array([-0.02763166,  0.01430723,  0.00295723, -0.02347479], dtype=float32),\n",
              " array([-0.02734552, -0.180857  ,  0.00248773,  0.2701397 ], dtype=float32),\n",
              " array([-0.03096266, -0.37601435,  0.00789053,  0.56360626], dtype=float32),\n",
              " array([-0.03848295, -0.18100402,  0.01916265,  0.27341962], dtype=float32),\n",
              " array([-0.04210303,  0.01383935,  0.02463104, -0.0131583 ], dtype=float32),\n",
              " array([-0.04182624,  0.20859955,  0.02436788, -0.2979692 ], dtype=float32),\n",
              " array([-0.03765425,  0.40336582,  0.01840849, -0.5828684 ], dtype=float32),\n",
              " array([-0.02958693,  0.20799087,  0.00675113, -0.28444386], dtype=float32),\n",
              " array([-0.02542712,  0.40301588,  0.00106225, -0.5749899 ], dtype=float32),\n",
              " array([-0.0173668 ,  0.59812295, -0.01043755, -0.867338  ], dtype=float32),\n",
              " array([-0.00540434,  0.7933853 , -0.02778431, -1.1632843 ], dtype=float32),\n",
              " array([ 0.01046337,  0.98885787, -0.05104999, -1.4645474 ], dtype=float32),\n",
              " array([ 0.03024052,  0.794397  , -0.08034094, -1.1882383 ], dtype=float32),\n",
              " array([ 0.04612847,  0.6004032 , -0.10410571, -0.92178106], dtype=float32),\n",
              " array([ 0.05813653,  0.40683034, -0.12254133, -0.6635456 ], dtype=float32),\n",
              " array([ 0.06627314,  0.213607  , -0.13581224, -0.41182107], dtype=float32),\n",
              " array([ 0.07054528,  0.02064536, -0.14404866, -0.16485004], dtype=float32),\n",
              " array([ 0.07095818,  0.21750408, -0.14734566, -0.4992838 ], dtype=float32),\n",
              " array([ 0.07530826,  0.02473315, -0.15733133, -0.25642368], dtype=float32),\n",
              " array([ 0.07580293, -0.16783363, -0.1624598 , -0.01720593], dtype=float32),\n",
              " array([ 0.07244626,  0.02920023, -0.16280393, -0.35641837], dtype=float32),\n",
              " array([ 0.07303026, -0.163278  , -0.16993229, -0.11917204], dtype=float32),\n",
              " array([ 0.0697647 ,  0.03381957, -0.17231573, -0.46027997], dtype=float32),\n",
              " array([ 0.07044109, -0.15850146, -0.18152134, -0.22648121], dtype=float32),\n",
              " array([ 0.06727106, -0.35062784, -0.18605097,  0.00389876], dtype=float32),\n",
              " array([ 0.0602585 , -0.1533926 , -0.18597299, -0.34123233], dtype=float32),\n",
              " array([ 0.05719065,  0.04382104, -0.19279763, -0.68631333], dtype=float32),\n",
              " array([ 0.05806707,  0.24102218, -0.2065239 , -1.0329665 ], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LiC3lv2yU1n"
      },
      "source": [
        "### Computing cumulative rewards\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "G_t &= r_t + \\gamma r_{t + 1} + \\gamma^2 r_{t + 2} + \\ldots \\\\\n",
        "&= \\sum_{i = t}^T \\gamma^{i - t} r_i \\\\\n",
        "&= r_t + \\gamma * G_{t + 1}\n",
        "\\end{align*}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "zYDny8M0yU1n"
      },
      "outputs": [],
      "source": [
        "def get_cumulative_rewards(\n",
        "    rewards,  # rewards at each step\n",
        "    gamma=0.99  # discount for reward\n",
        "):\n",
        "    \"\"\"\n",
        "    Take a list of immediate rewards r(s,a) for the whole session\n",
        "    and compute cumulative returns (a.k.a. G(s,a) in Sutton '16).\n",
        "\n",
        "    G_t = r_t + gamma*r_{t+1} + gamma^2*r_{t+2} + ...\n",
        "\n",
        "    A simple way to compute cumulative rewards is to iterate from the last\n",
        "    to the first timestep and compute G_t = r_t + gamma*G_{t+1} recurrently\n",
        "\n",
        "    You must return an array/list of cumulative rewards with as many elements as in the initial rewards.\n",
        "    \"\"\"\n",
        "    G = [rewards[-1]]\n",
        "    for t in range(len(rewards) - 2, -1, -1):\n",
        "        r_t = rewards[t] + G[-1] * gamma\n",
        "        G.append(r_t)\n",
        "    return G[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKVDNWekyU1n",
        "outputId": "d335041b-968d-4db7-fc1a-c8d5a1d445c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "looks good!\n"
          ]
        }
      ],
      "source": [
        "get_cumulative_rewards(rewards)\n",
        "assert len(get_cumulative_rewards(list(range(100)))) == 100\n",
        "assert np.allclose(\n",
        "    get_cumulative_rewards([0, 0, 1, 0, 0, 1, 0], gamma=0.9),\n",
        "    [1.40049, 1.5561, 1.729, 0.81, 0.9, 1.0, 0.0])\n",
        "assert np.allclose(\n",
        "    get_cumulative_rewards([0, 0, 1, -2, 3, -4, 0], gamma=0.5),\n",
        "    [0.0625, 0.125, 0.25, -1.5, 1.0, -4.0, 0.0])\n",
        "assert np.allclose(\n",
        "    get_cumulative_rewards([0, 0, 1, 2, 3, 4, 0], gamma=0),\n",
        "    [0, 0, 1, 2, 3, 4, 0])\n",
        "print(\"looks good!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNIBQ3BRyU1n"
      },
      "source": [
        "#### Loss function and updates\n",
        "\n",
        "We now need to define objective and update over policy gradient.\n",
        "\n",
        "Our objective function is\n",
        "\n",
        "$$ J \\approx  { 1 \\over N } \\sum_{s_i,a_i} G(s_i,a_i) $$\n",
        "\n",
        "REINFORCE defines a way to compute the gradient of the expected reward with respect to policy parameters. The formula is as follows:\n",
        "\n",
        "$$ \\nabla_\\theta \\hat J(\\theta) \\approx { 1 \\over N } \\sum_{s_i, a_i} \\nabla_\\theta \\log \\pi_\\theta (a_i \\mid s_i) \\cdot G_t(s_i, a_i) $$\n",
        "\n",
        "We can abuse PyTorch's capabilities for automatic differentiation by defining our objective function as follows:\n",
        "\n",
        "$$ \\hat J(\\theta) \\approx { 1 \\over N } \\sum_{s_i, a_i} \\log \\pi_\\theta (a_i \\mid s_i) \\cdot G_t(s_i, a_i) $$\n",
        "\n",
        "When you compute the gradient of that function with respect to network weights $\\theta$, it will become exactly the policy gradient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZKwFV31yU1n"
      },
      "outputs": [],
      "source": [
        "# Your code: define optimizers\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
        "\n",
        "\n",
        "def train_on_session(states, actions, rewards, gamma=0.99, entropy_coef=1e-2):\n",
        "    \"\"\"\n",
        "    Takes a sequence of states, actions and rewards produced by generate_session.\n",
        "    Updates agent's weights by following the policy gradient above.\n",
        "    Please use Adam optimizer with default parameters.\n",
        "    \"\"\"\n",
        "\n",
        "    # cast everything into torch tensors\n",
        "    states = torch.tensor(states, dtype=torch.float32)\n",
        "    actions = torch.tensor(actions, dtype=torch.int64)\n",
        "    cumulative_returns = np.array(get_cumulative_rewards(rewards, gamma))\n",
        "    cumulative_returns = torch.tensor(cumulative_returns, dtype=torch.float32)\n",
        "\n",
        "    # predict logits, probas and log-probas using an agent.\n",
        "    logits = model(states)\n",
        "    probs = nn.functional.softmax(logits, -1)\n",
        "    log_probs = nn.functional.log_softmax(logits, -1)\n",
        "\n",
        "    assert all(isinstance(v, torch.Tensor) for v in [logits, probs, log_probs]), \\\n",
        "        \"please use compute using torch tensors and don't use predict_probs function\"\n",
        "\n",
        "    # select log-probabilities for chosen actions, log pi(a_i|s_i)\n",
        "    log_probs_for_actions = torch.sum(\n",
        "        log_probs * F.one_hot(actions, env.action_space.n), dim=1)\n",
        "\n",
        "    # Compute loss here. Don't forgen entropy regularization with `entropy_coef`\n",
        "    entropy = <YOUR CODE>\n",
        "    loss = <YOUR CODE>\n",
        "\n",
        "    # Gradient descent step\n",
        "    <YOUR CODE>\n",
        "\n",
        "    # technical: return session rewards to print them later\n",
        "    return np.sum(rewards)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btkAjBA5yU1n"
      },
      "source": [
        "### The actual training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qs9NuGinyU1n"
      },
      "outputs": [],
      "source": [
        "for i in range(100):\n",
        "    rewards = [train_on_session(*generate_session(env)) for _ in range(100)]  # generate new sessions\n",
        "\n",
        "    print(\"mean reward: %.3f\" % (np.mean(rewards)))\n",
        "\n",
        "    if np.mean(rewards) > 500:\n",
        "        print(\"You Win!\")  # but you can train even further\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VDJIaz9yU1n"
      },
      "source": [
        "### Results & video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqbIrS96yU1o"
      },
      "outputs": [],
      "source": [
        "# Record sessions\n",
        "\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "\n",
        "with gym.make(\"CartPole-v1\", render_mode=\"rgb_array\") as env, RecordVideo(\n",
        "    env=env, video_folder=\"./videos\"\n",
        ") as env_monitor:\n",
        "    sessions = [generate_session(env_monitor) for _ in range(10)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNAFM6FNyU1o"
      },
      "outputs": [],
      "source": [
        "# Show video. This may not work in some setups. If it doesn't\n",
        "# work for you, you can download the videos and view them locally.\n",
        "\n",
        "from pathlib import Path\n",
        "from base64 import b64encode\n",
        "from IPython.display import HTML\n",
        "\n",
        "video_paths = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
        "video_path = video_paths[-1]  # You can also try other indices\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    # https://stackoverflow.com/a/57378660/1214547\n",
        "    with video_path.open('rb') as fp:\n",
        "        mp4 = fp.read()\n",
        "    data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "else:\n",
        "    data_url = str(video_path)\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=\"640\" height=\"480\" controls>\n",
        "  <source src=\"{}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\".format(data_url))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}