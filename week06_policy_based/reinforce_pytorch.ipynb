{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efgs4wdEyU1f"
      },
      "source": [
        "# REINFORCE in PyTorch\n",
        "\n",
        "Just like we did before for Q-learning, this time we'll design a PyTorch network to learn `CartPole-v0` via policy gradient (REINFORCE).\n",
        "\n",
        "Most of the code in this notebook is taken from approximate Q-learning, so you'll find it more or less familiar and even simpler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVaFXKRwyU1g",
        "outputId": "57bf4100-ffce-41ba-b7d7-0e2c1daf20bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "(Reading database ... 123634 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../1-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../3-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../5-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../7-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.12_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../8-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.12_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.36.1)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio_ffmpeg>=0.2.0->moviepy) (75.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.12.14)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 50 not upgraded.\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg) (75.1.0)\n",
            "Starting virtual X frame buffer: Xvfb.\n"
          ]
        }
      ],
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "    !pip install -q gymnasium\n",
        "    !pip install moviepy\n",
        "    !apt install ffmpeg\n",
        "    !pip install imageio-ffmpeg\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4HOq-CpryU1h"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YAru4d4VyU1i"
      },
      "outputs": [],
      "source": [
        "# also you need to install ffmpeg if not installed\n",
        "# for MacOS: ! brew install ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8-BpqdYyU1i"
      },
      "source": [
        "A caveat: with some versions of `pyglet`, the following cell may crash with `NameError: name 'base' is not defined`. The corresponding bug report is [here](https://github.com/pyglet/pyglet/issues/134). If you see this error, try restarting the kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "AATaX0SYyU1j",
        "outputId": "9383f04a-e579-4efe-f5e1-91a5fdbde340"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ec2e0bc4580>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "\n",
        "# gym compatibility: unwrap TimeLimit\n",
        "if hasattr(env, '_max_episode_steps'):\n",
        "    env = env.env\n",
        "\n",
        "env.reset()\n",
        "n_actions = env.action_space.n\n",
        "state_dim = env.observation_space.shape\n",
        "\n",
        "plt.imshow(env.render())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xd4juOoyU1j"
      },
      "source": [
        "# Building the network for REINFORCE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIqWC71UyU1k"
      },
      "source": [
        "For REINFORCE algorithm, we'll need a model that predicts action probabilities given states.\n",
        "\n",
        "For numerical stability, please __do not include the softmax layer into your network architecture__.\n",
        "We'll use softmax or log-softmax where appropriate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "B0tLtBnEyU1k"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RSSwjjjyU1l",
        "outputId": "4ea9f70c-ff4c-4c93-d738-6109bd25eb5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 2\n"
          ]
        }
      ],
      "source": [
        "# Build a simple neural network that predicts policy logits.\n",
        "# Keep it simple: CartPole isn't worth deep architectures.\n",
        "n_inputs = env.reset()[0].shape[0]\n",
        "n_hidden = 16\n",
        "n_outputs = env.action_space.n\n",
        "print(n_inputs, n_outputs)\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(n_inputs, n_hidden),\n",
        "    # nn.BatchNorm1d(n_hidden),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Linear(n_hidden, n_hidden),\n",
        "    # nn.BatchNorm1d(n_hidden),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Linear(n_hidden, n_outputs),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ahdnFbyU1m"
      },
      "source": [
        "#### Predict function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcGLoV9pyU1m"
      },
      "source": [
        "Note: output value of this function is not a torch tensor, it's a numpy array.\n",
        "So, here gradient calculation is not needed.\n",
        "<br>\n",
        "Use [no_grad](https://pytorch.org/docs/stable/autograd.html#torch.autograd.no_grad)\n",
        "to suppress gradient calculation.\n",
        "<br>\n",
        "Also, `.detach()` (or legacy `.data` property) can be used instead, but there is a difference:\n",
        "<br>\n",
        "With `.detach()` computational graph is built but then disconnected from a particular tensor,\n",
        "so `.detach()` should be used if that graph is needed for backprop via some other (not detached) tensor;\n",
        "<br>\n",
        "In contrast, no graph is built by any operation in `no_grad()` context, thus it's preferable here."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cpu\""
      ],
      "metadata": {
        "id": "x275klweNPV_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "i-4L5BCtyU1m"
      },
      "outputs": [],
      "source": [
        "def predict_probs(states):\n",
        "    \"\"\"\n",
        "    Predict action probabilities given states.\n",
        "    :param states: numpy array of shape [batch, state_shape]\n",
        "    :returns: numpy array of shape [batch, n_actions]\n",
        "    \"\"\"\n",
        "    # convert states, compute logits, use softmax to get probability\n",
        "    states = torch.from_numpy(states).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(states)\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "\n",
        "    return probs.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()[0].shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XVpl-YJNcwD",
        "outputId": "28ce4a7c-0c79-487a-b8eb-e511d9dbbcc5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rjeU88vMyU1m"
      },
      "outputs": [],
      "source": [
        "test_states = np.array([env.reset()[0] for _ in range(5)])\n",
        "test_probas = predict_probs(test_states)\n",
        "assert isinstance(test_probas, np.ndarray), \\\n",
        "    \"you must return np array and not %s\" % type(test_probas)\n",
        "assert tuple(test_probas.shape) == (test_states.shape[0], env.action_space.n), \\\n",
        "    \"wrong output shape: %s\" % str(np.shape(test_probas))\n",
        "assert np.allclose(np.sum(test_probas, axis=1), 1), \"probabilities do not sum to 1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsKrnycWyU1m"
      },
      "source": [
        "### Play the game\n",
        "\n",
        "We can now use our newly built agent to play the game."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "24iSwdvCyU1m"
      },
      "outputs": [],
      "source": [
        "def generate_session(env, t_max=1000):\n",
        "    \"\"\"\n",
        "    Play a full session with REINFORCE agent.\n",
        "    Returns sequences of states, actions, and rewards.\n",
        "    \"\"\"\n",
        "    # arrays to record session\n",
        "    states, actions, rewards = [], [], []\n",
        "\n",
        "    s = env.reset()[0]\n",
        "\n",
        "    for t in range(t_max):\n",
        "        # action probabilities array aka pi(a|s)\n",
        "        action_probs = predict_probs(np.array([s]))[0]\n",
        "\n",
        "        # Sample action with given probabilities.\n",
        "        a = np.random.choice(env.action_space.n, p=action_probs)\n",
        "\n",
        "        new_s, r, terminated, truncated, info = env.step(a)\n",
        "\n",
        "        # record session history to train later\n",
        "        states.append(s)\n",
        "        actions.append(a)\n",
        "        rewards.append(r)\n",
        "\n",
        "        s = new_s\n",
        "        if terminated or truncated:\n",
        "            break\n",
        "\n",
        "    return states, actions, rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-7u6Xhc4yU1n"
      },
      "outputs": [],
      "source": [
        "# test it\n",
        "states, actions, rewards = generate_session(env)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# everything -- for only ONE session\n",
        "# e.g. states of ONE session: s0, s1, s2, ... si\n",
        "states"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMMo7s97O_jZ",
        "outputId": "a64bc3e6-05b2-4a4c-b027-0e07df93a3a4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ 0.02836876, -0.04433779, -0.04202638,  0.03551647], dtype=float32),\n",
              " array([ 0.027482  ,  0.15136084, -0.04131605, -0.2701244 ], dtype=float32),\n",
              " array([ 0.03050922,  0.3470473 , -0.04671854, -0.57554704], dtype=float32),\n",
              " array([ 0.03745016,  0.1526103 , -0.05822948, -0.29794005], dtype=float32),\n",
              " array([ 0.04050237,  0.34851187, -0.06418828, -0.60840416], dtype=float32),\n",
              " array([ 0.04747261,  0.5444697 , -0.07635636, -0.920594  ], dtype=float32),\n",
              " array([ 0.058362  ,  0.3504581 , -0.09476824, -0.65285146], dtype=float32),\n",
              " array([ 0.06537116,  0.54676306, -0.10782527, -0.9738079 ], dtype=float32),\n",
              " array([ 0.07630643,  0.74315345, -0.12730142, -1.2983218 ], dtype=float32),\n",
              " array([ 0.09116949,  0.5498567 , -0.15326786, -1.0480486 ], dtype=float32),\n",
              " array([ 0.10216663,  0.35706377, -0.17422883, -0.80713373], dtype=float32),\n",
              " array([ 0.10930791,  0.16470304, -0.19037151, -0.5739255 ], dtype=float32),\n",
              " array([ 0.11260197, -0.02731193, -0.20185003, -0.34673822], dtype=float32),\n",
              " array([ 0.11205573, -0.21907659, -0.20878479, -0.12387297], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LiC3lv2yU1n"
      },
      "source": [
        "### Computing cumulative rewards\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "G_t &= r_t + \\gamma r_{t + 1} + \\gamma^2 r_{t + 2} + \\ldots \\\\\n",
        "&= \\sum_{i = t}^T \\gamma^{i - t} r_i \\\\\n",
        "&= r_t + \\gamma * G_{t + 1}\n",
        "\\end{align*}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zYDny8M0yU1n"
      },
      "outputs": [],
      "source": [
        "def get_cumulative_rewards(\n",
        "    rewards,  # rewards at each step\n",
        "    gamma=0.99  # discount for reward\n",
        "):\n",
        "    \"\"\"\n",
        "    Take a list of immediate rewards r(s,a) for the whole session\n",
        "    and compute cumulative returns (a.k.a. G(s,a) in Sutton '16).\n",
        "\n",
        "    G_t = r_t + gamma*r_{t+1} + gamma^2*r_{t+2} + ...\n",
        "\n",
        "    A simple way to compute cumulative rewards is to iterate from the last\n",
        "    to the first timestep and compute G_t = r_t + gamma*G_{t+1} recurrently\n",
        "\n",
        "    You must return an array/list of cumulative rewards with as many elements as in the initial rewards.\n",
        "    \"\"\"\n",
        "    G = [rewards[-1]]\n",
        "    for t in range(len(rewards) - 2, -1, -1):\n",
        "        r_t = rewards[t] + G[-1] * gamma\n",
        "        G.append(r_t)\n",
        "    return G[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKVDNWekyU1n",
        "outputId": "e216696f-0a0e-4f8d-e096-79ceee8a3168"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "looks good!\n"
          ]
        }
      ],
      "source": [
        "get_cumulative_rewards(rewards)\n",
        "assert len(get_cumulative_rewards(list(range(100)))) == 100\n",
        "assert np.allclose(\n",
        "    get_cumulative_rewards([0, 0, 1, 0, 0, 1, 0], gamma=0.9),\n",
        "    [1.40049, 1.5561, 1.729, 0.81, 0.9, 1.0, 0.0])\n",
        "assert np.allclose(\n",
        "    get_cumulative_rewards([0, 0, 1, -2, 3, -4, 0], gamma=0.5),\n",
        "    [0.0625, 0.125, 0.25, -1.5, 1.0, -4.0, 0.0])\n",
        "assert np.allclose(\n",
        "    get_cumulative_rewards([0, 0, 1, 2, 3, 4, 0], gamma=0),\n",
        "    [0, 0, 1, 2, 3, 4, 0])\n",
        "print(\"looks good!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNIBQ3BRyU1n"
      },
      "source": [
        "#### Loss function and updates\n",
        "\n",
        "We now need to define objective and update over policy gradient.\n",
        "\n",
        "Our objective function is\n",
        "\n",
        "$$ J \\approx  { 1 \\over N } \\sum_{s_i,a_i} G(s_i,a_i) $$\n",
        "\n",
        "REINFORCE defines a way to compute the gradient of the expected reward with respect to policy parameters. The formula is as follows:\n",
        "\n",
        "$$ \\nabla_\\theta \\hat J(\\theta) \\approx { 1 \\over N } \\sum_{s_i, a_i} \\nabla_\\theta \\log \\pi_\\theta (a_i \\mid s_i) \\cdot G_t(s_i, a_i) $$\n",
        "\n",
        "We can abuse PyTorch's capabilities for automatic differentiation by defining our objective function as follows:\n",
        "\n",
        "$$ \\hat J(\\theta) \\approx { 1 \\over N } \\sum_{s_i, a_i} \\log \\pi_\\theta (a_i \\mid s_i) \\cdot G_t(s_i, a_i) $$\n",
        "\n",
        "When you compute the gradient of that function with respect to network weights $\\theta$, it will become exactly the policy gradient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PZKwFV31yU1n"
      },
      "outputs": [],
      "source": [
        "# Your code: define optimizers\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
        "\n",
        "\n",
        "def train_on_session(states, actions, rewards, gamma=0.99, entropy_coef=1e-2):\n",
        "    \"\"\"\n",
        "    Takes a sequence of states, actions and rewards produced by generate_session.\n",
        "    Updates agent's weights by following the policy gradient above.\n",
        "    Please use Adam optimizer with default parameters.\n",
        "    \"\"\"\n",
        "\n",
        "    # cast everything into torch tensors\n",
        "    states = torch.tensor(states, dtype=torch.float32)\n",
        "    actions = torch.tensor(actions, dtype=torch.int64)\n",
        "    cumulative_returns = np.array(get_cumulative_rewards(rewards, gamma))\n",
        "    cumulative_returns = torch.tensor(cumulative_returns, dtype=torch.float32)\n",
        "\n",
        "    # predict logits, probas and log-probas using an agent.\n",
        "    logits = model(states)\n",
        "    probs = nn.functional.softmax(logits, -1)\n",
        "    log_probs = nn.functional.log_softmax(logits, -1)\n",
        "\n",
        "    assert all(isinstance(v, torch.Tensor) for v in [logits, probs, log_probs]), \\\n",
        "        \"please use compute using torch tensors and don't use predict_probs function\"\n",
        "\n",
        "    # print(log_probs.size(), F.one_hot(actions, env.action_space.n).size(), cumulative_returns.size())\n",
        "\n",
        "    # select log-probabilities for chosen actions, log pi(a_i|s_i)\n",
        "    log_probs_for_actions = torch.sum(\n",
        "        log_probs * F.one_hot(actions, env.action_space.n),\n",
        "        dim=1\n",
        "    )\n",
        "\n",
        "    # Compute loss here. Don't forgen entropy regularization with `entropy_coef`\n",
        "    entropy = -(probs * log_probs).sum(dim=-1).mean(dim=0)\n",
        "    loss = -(log_probs_for_actions * cumulative_returns).mean() - entropy_coef * entropy\n",
        "    # ! no gradients for cumulative returns! it's just variable (scalar)\n",
        "\n",
        "    # Gradient descent step\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # technical: return session rewards to print them later\n",
        "    return np.sum(rewards)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btkAjBA5yU1n"
      },
      "source": [
        "### The actual training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs9NuGinyU1n",
        "outputId": "d6f9802b-030c-4efa-b6fa-59fabbef7a64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean reward: 165.780\n",
            "mean reward: 180.550\n",
            "mean reward: 135.680\n",
            "mean reward: 224.890\n",
            "mean reward: 383.870\n",
            "mean reward: 320.840\n",
            "mean reward: 254.430\n",
            "mean reward: 190.090\n",
            "mean reward: 251.060\n",
            "mean reward: 353.390\n",
            "mean reward: 228.160\n",
            "mean reward: 208.260\n",
            "mean reward: 293.250\n",
            "mean reward: 628.810\n",
            "You Win!\n"
          ]
        }
      ],
      "source": [
        "for i in range(100):\n",
        "    rewards = [train_on_session(*generate_session(env)) for _ in range(100)]  # generate new sessions\n",
        "\n",
        "    print(\"mean reward: %.3f\" % (np.mean(rewards)))\n",
        "\n",
        "    if np.mean(rewards) > 500:\n",
        "        print(\"You Win!\")  # but you can train even further\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VDJIaz9yU1n"
      },
      "source": [
        "### Results & video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqbIrS96yU1o"
      },
      "outputs": [],
      "source": [
        "# Record sessions\n",
        "\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "\n",
        "with gym.make(\"CartPole-v1\", render_mode=\"rgb_array\") as env, RecordVideo(\n",
        "    env=env, video_folder=\"./videos\"\n",
        ") as env_monitor:\n",
        "    sessions = [generate_session(env_monitor) for _ in range(10)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNAFM6FNyU1o"
      },
      "outputs": [],
      "source": [
        "# Show video. This may not work in some setups. If it doesn't\n",
        "# work for you, you can download the videos and view them locally.\n",
        "\n",
        "from pathlib import Path\n",
        "from base64 import b64encode\n",
        "from IPython.display import HTML\n",
        "\n",
        "video_paths = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
        "video_path = video_paths[-1]  # You can also try other indices\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    # https://stackoverflow.com/a/57378660/1214547\n",
        "    with video_path.open('rb') as fp:\n",
        "        mp4 = fp.read()\n",
        "    data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "else:\n",
        "    data_url = str(video_path)\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=\"640\" height=\"480\" controls>\n",
        "  <source src=\"{}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\".format(data_url))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}